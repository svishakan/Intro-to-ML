{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple ID3 (Iterative Dichotomiser 3) Decision Tree Python Implementation\n",
    "\n",
    "### By Vishakan Subramanian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(p):\n",
    "    \"\"\"Calculate the entropy of a given numerical value.\"\"\"\n",
    "    \n",
    "    if p != 0:\n",
    "        return -p * math.log2(p)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Total Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_total_entropy(data):\n",
    "    \"\"\"Calculates the total entropy of the given dataset.\"\"\"\n",
    "    \n",
    "    output_labels = list(set(label[3] for label in data))\n",
    "    output_probs = []\n",
    "    #print(output_labels)\n",
    "\n",
    "    for label in output_labels:\n",
    "        count = 0\n",
    "        \n",
    "        for data_row in data:\n",
    "            if data_row[-1] == label:    #Assumes that the classifying label is in the last column\n",
    "                count += 1\n",
    "        \n",
    "        output_probs.append((count/len(data)))\n",
    "        \n",
    "    entropy = round(sum(calc_entropy(prob) for prob in output_probs), 3)\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Information Gain by filtering each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_info_gain(total_entropy, feature_data, full_dataset):\n",
    "    \"\"\"Calculates the information gained by branching out towards a specific feature. \"\"\"\n",
    "    \n",
    "    feature_labels = list(set(label for label in feature_data))\n",
    "    feature_probs = []\n",
    "    subfeature_entropy_values = []\n",
    "    info_gain = total_entropy\n",
    "    #print(feature_labels)\n",
    "    \n",
    "    for label in feature_labels:\n",
    "        count = 0\n",
    "        indices = []\n",
    "        filtered_data = []\n",
    "        \n",
    "        \n",
    "        for i in range(len(feature_data)):\n",
    "            if feature_data[i] == label:\n",
    "                count += 1\n",
    "                indices.append(i)\n",
    "                \n",
    "                \n",
    "        for i in range(len(full_dataset)):\n",
    "            if i in indices:\n",
    "                indices.remove(i)\n",
    "                filtered_data.append(full_dataset[i])\n",
    "        \n",
    "        subfeature_entropy_values.append(calc_total_entropy(filtered_data))\n",
    "    \n",
    "        feature_probs.append((count/len(feature_data)))\n",
    "    \n",
    "    #print(subfeature_entropy_values, feature_probs)\n",
    "    \n",
    "    entropy_lost = sum(subfeature_entropy_values[i] * feature_probs[i] for i in range(len(feature_probs)))\n",
    "    \n",
    "    \n",
    "    info_gain = total_entropy - entropy_lost\n",
    "    #print(info_gain)\n",
    "    \n",
    "    return round(info_gain, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Information Gain for each feature of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info_gains(features, data):\n",
    "    \"\"\"Print the information gain by branching out towards all existing features of the dataset. \"\"\"\n",
    "    \n",
    "    total_entropy = calc_total_entropy(data)\n",
    "    feature_info_gains = []\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        feature_values = [feature_set[i] for feature_set in data]\n",
    "        feature_info_gains.append((features[i], calc_info_gain(total_entropy, feature_values, data)))\n",
    "    \n",
    "    feature_info_gains.sort(key = lambda x: x[1], reverse = True)\n",
    "    \n",
    "    print(\"Feature ----- Gain\\n\")\n",
    "    \n",
    "    for gains in feature_info_gains:\n",
    "        \n",
    "        print(\"{0} ----- {1}\".format(gains[0], gains[1]))\n",
    "    \n",
    "    if feature_info_gains[0][0] == features[-1]:    # if the maximum gain feature is the o/p feature in list\n",
    "        return feature_info_gains[1]\n",
    "    else:\n",
    "        return feature_info_gains[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree(features, data):\n",
    "    \"\"\"Make a decision tree based on branching out towards maximum information gain feature.\"\"\"\n",
    "    \n",
    "    iter = 1\n",
    "    \n",
    "    while True:\n",
    "        print(\"Iteration:\", iter, \"\\n\")\n",
    "        iter += 1\n",
    "        max_gain_feature, max_info_gain = print_info_gains(features, data)\n",
    "        \n",
    "        if max_info_gain == 0:\n",
    "            print(\"\\n\\t\\tClassification complete!\\n\")\n",
    "            break\n",
    "        \n",
    "        feature_index = features.index(max_gain_feature)\n",
    "        temp_set = []\n",
    "        flag = True\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            temp_set.append([i, data[i][feature_index], data[i][-1]])\n",
    "        \n",
    "        #print(temp_set)\n",
    "        feature_values = list(set(value[1] for value in temp_set))\n",
    "        \n",
    "        temp_set.sort(key = lambda x: x[1])\n",
    "        \n",
    "        for value in feature_values:\n",
    "            feat_flag = True\n",
    "            prev = temp_set[0][2]\n",
    "            \n",
    "            for i in range(len(temp_set)):\n",
    "                if value != temp_set[i][1] and (i + 1) < len(temp_set):\n",
    "                    prev = temp_set[i + 1][1]\n",
    "                    break\n",
    "            \n",
    "                if temp_set[i][1] != prev:\n",
    "                    feat_flag = False\n",
    "            \n",
    "            #print(feat_flag, value)\n",
    "            if feat_flag == True:\n",
    "                decrement = 1\n",
    "                del_indices = []\n",
    "                print(\"\\nRemoved Data:\")\n",
    "                \n",
    "                for i in range(len(temp_set)):\n",
    "                    if value == temp_set[i][1] and (temp_set[i][0] - decrement) < len(data):\n",
    "                        print(temp_set[i])\n",
    "                        del_indices.append(temp_set[i][0])\n",
    "                        #del data[temp_set[i][0]]\n",
    "                        decrement += 1\n",
    "                        \n",
    "                for index in sorted(del_indices, reverse=True):   #discontinguous array, so sorting\n",
    "                    del data[index]                               #necessary to remove properly\n",
    "\n",
    "\n",
    "                print(\"\\nRemaining Data:\")\n",
    "                for d in data:\n",
    "                    print(d)\n",
    "                \n",
    "                temp_set = []\n",
    "                for i in range(len(data)):   #bug fix, recalculate the temp set to avoid index mismatch\n",
    "                    temp_set.append([i, data[i][feature_index], data[i][-1]])\n",
    "                    \n",
    "                print(\"\\n\")\n",
    "                #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset-1 : Activity is the output label. Deadline?, Party? and Lazy? are feature labels.\n",
    "\n",
    "features = [\"Deadline?\", \"Party?\", \"Lazy?\", \"Activity\"]\n",
    "            \n",
    "data = [[\"Urgent\", \"Yes\", \"Yes\", \"Party\"],\n",
    "        [\"Urgent\", \"No\", \"Yes\", \"Study\"],\n",
    "        [\"Near\", \"Yes\", \"Yes\", \"Party\"],\n",
    "        [\"None\", \"Yes\", \"No\", \"Party\"],\n",
    "        [\"None\", \"No\", \"Yes\", \"Pub\"],\n",
    "        [\"None\", \"Yes\", \"No\", \"Party\"],\n",
    "        [\"Near\", \"No\", \"No\", \"Study\"],\n",
    "        [\"Near\", \"No\", \"Yes\", \"TV\"],\n",
    "        [\"Near\", \"Yes\", \"Yes\", \"Party\"],\n",
    "        [\"Urgent\", \"No\", \"No\", \"Study\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 \n",
      "\n",
      "Feature ----- Gain\n",
      "\n",
      "Activity ----- 1.685\n",
      "Party? ----- 1.0\n",
      "Deadline? ----- 0.534\n",
      "Lazy? ----- 0.21\n",
      "\n",
      "Removed Data:\n",
      "[0, 'Yes', 'Party']\n",
      "[2, 'Yes', 'Party']\n",
      "[3, 'Yes', 'Party']\n",
      "[5, 'Yes', 'Party']\n",
      "[8, 'Yes', 'Party']\n",
      "\n",
      "Remaining Data:\n",
      "['Urgent', 'No', 'Yes', 'Study']\n",
      "['None', 'No', 'Yes', 'Pub']\n",
      "['Near', 'No', 'No', 'Study']\n",
      "['Near', 'No', 'Yes', 'TV']\n",
      "['Urgent', 'No', 'No', 'Study']\n",
      "\n",
      "\n",
      "Iteration: 2 \n",
      "\n",
      "Feature ----- Gain\n",
      "\n",
      "Activity ----- 1.371\n",
      "Deadline? ----- 0.971\n",
      "Lazy? ----- 0.42\n",
      "Party? ----- 0.0\n",
      "\n",
      "Removed Data:\n",
      "[0, 'Urgent', 'Study']\n",
      "[4, 'Urgent', 'Study']\n",
      "\n",
      "Remaining Data:\n",
      "['None', 'No', 'Yes', 'Pub']\n",
      "['Near', 'No', 'No', 'Study']\n",
      "['Near', 'No', 'Yes', 'TV']\n",
      "\n",
      "\n",
      "Iteration: 3 \n",
      "\n",
      "Feature ----- Gain\n",
      "\n",
      "Activity ----- 1.585\n",
      "Deadline? ----- 0.918\n",
      "Lazy? ----- 0.918\n",
      "Party? ----- 0.0\n",
      "\n",
      "Removed Data:\n",
      "[0, 'None', 'Pub']\n",
      "\n",
      "Remaining Data:\n",
      "['Near', 'No', 'No', 'Study']\n",
      "['Near', 'No', 'Yes', 'TV']\n",
      "\n",
      "\n",
      "Iteration: 4 \n",
      "\n",
      "Feature ----- Gain\n",
      "\n",
      "Lazy? ----- 1.0\n",
      "Activity ----- 1.0\n",
      "Deadline? ----- 0.0\n",
      "Party? ----- 0.0\n",
      "\n",
      "Removed Data:\n",
      "[1, 'Yes', 'TV']\n",
      "\n",
      "Remaining Data:\n",
      "['Near', 'No', 'No', 'Study']\n",
      "\n",
      "\n",
      "Iteration: 5 \n",
      "\n",
      "Feature ----- Gain\n",
      "\n",
      "Deadline? ----- 0.0\n",
      "Party? ----- 0.0\n",
      "Lazy? ----- 0.0\n",
      "Activity ----- 0.0\n",
      "\n",
      "\t\tClassification complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "make_tree(features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 \n",
      "\n",
      "Feature ----- Gain\n",
      "\n",
      "Attractive? ----- 0.954\n",
      "Hair ----- 0.454\n",
      "Eyes ----- 0.347\n",
      "Height ----- 0.003\n",
      "\n",
      "Removed Data:\n",
      "[5, 'Red', 'Yes']\n",
      "\n",
      "Remaining Data:\n",
      "['Small', 'Blonde', 'Brown', 'No']\n",
      "['Tall', 'Dark', 'Brown', 'No']\n",
      "['Tall', 'Blonde', 'Blue', 'Yes']\n",
      "['Tall', 'Dark', 'Blue', 'No']\n",
      "['Small', 'Dark', 'Blue', 'No']\n",
      "['Tall', 'Blonde', 'Brown', 'No']\n",
      "['Small', 'Blonde', 'Blue', 'Yes']\n",
      "\n",
      "\n",
      "\n",
      "Removed Data:\n",
      "[1, 'Dark', 'No']\n",
      "[3, 'Dark', 'No']\n",
      "[4, 'Dark', 'No']\n",
      "\n",
      "Remaining Data:\n",
      "['Small', 'Blonde', 'Brown', 'No']\n",
      "['Tall', 'Blonde', 'Blue', 'Yes']\n",
      "['Tall', 'Blonde', 'Brown', 'No']\n",
      "['Small', 'Blonde', 'Blue', 'Yes']\n",
      "\n",
      "\n",
      "Iteration: 2 \n",
      "\n",
      "Feature ----- Gain\n",
      "\n",
      "Eyes ----- 1.0\n",
      "Attractive? ----- 1.0\n",
      "Height ----- 0.0\n",
      "Hair ----- 0.0\n",
      "\n",
      "Removed Data:\n",
      "[0, 'Brown', 'No']\n",
      "[2, 'Brown', 'No']\n",
      "\n",
      "Remaining Data:\n",
      "['Tall', 'Blonde', 'Blue', 'Yes']\n",
      "['Small', 'Blonde', 'Blue', 'Yes']\n",
      "\n",
      "\n",
      "Iteration: 3 \n",
      "\n",
      "Feature ----- Gain\n",
      "\n",
      "Height ----- 0.0\n",
      "Hair ----- 0.0\n",
      "Eyes ----- 0.0\n",
      "Attractive? ----- 0.0\n",
      "\n",
      "\t\tClassification complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Dataset-2 : Attractive? is the output label. Height, Hair and Eyes are feature labels.\n",
    "\n",
    "features = [\"Height\", \"Hair\", \"Eyes\", \"Attractive?\"]\n",
    "\n",
    "data = [[\"Small\", \"Blonde\", \"Brown\", \"No\"],\n",
    "        [\"Tall\", \"Dark\", \"Brown\", \"No\"],\n",
    "        [\"Tall\", \"Blonde\", \"Blue\", \"Yes\"],\n",
    "        [\"Tall\", \"Dark\", \"Blue\", \"No\"],\n",
    "        [\"Small\", \"Dark\", \"Blue\", \"No\"],\n",
    "        [\"Tall\", \"Red\", \"Blue\", \"Yes\"],\n",
    "        [\"Tall\", \"Blonde\", \"Brown\", \"No\"],\n",
    "        [\"Small\", \"Blonde\", \"Blue\", \"Yes\"]]\n",
    "\n",
    "make_tree(features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 \n",
      "\n",
      "Feature ----- Gain\n",
      "\n",
      "Pub ----- 0.954\n",
      "Student ----- 0.548\n",
      "Drink ----- 0.204\n",
      "Gender ----- 0.048\n",
      "\n",
      "Removed Data:\n",
      "[0, 'T', 'T']\n",
      "[4, 'T', 'T']\n",
      "[6, 'T', 'T']\n",
      "[7, 'T', 'T']\n",
      "\n",
      "Remaining Data:\n",
      "['Beer', 'T', 'F', 'T']\n",
      "['Vodka', 'T', 'F', 'F']\n",
      "['Vodka', 'T', 'F', 'F']\n",
      "['Vodka', 'F', 'F', 'F']\n",
      "\n",
      "\n",
      "Iteration: 2 \n",
      "\n",
      "Feature ----- Gain\n",
      "\n",
      "Drink ----- 0.811\n",
      "Pub ----- 0.811\n",
      "Gender ----- 0.123\n",
      "Student ----- 0.0\n",
      "\n",
      "Removed Data:\n",
      "[1, 'Vodka', 'F']\n",
      "[2, 'Vodka', 'F']\n",
      "[3, 'Vodka', 'F']\n",
      "\n",
      "Remaining Data:\n",
      "['Beer', 'T', 'F', 'T']\n",
      "\n",
      "\n",
      "Iteration: 3 \n",
      "\n",
      "Feature ----- Gain\n",
      "\n",
      "Drink ----- 0.0\n",
      "Gender ----- 0.0\n",
      "Student ----- 0.0\n",
      "Pub ----- 0.0\n",
      "\n",
      "\t\tClassification complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Dataset-3 : Goes to Pub? is the output label. Drink, Gender, Student are feature labels.\n",
    "\n",
    "features = [\"Drink\", \"Gender\", \"Student\", \"Pub\"]\n",
    "\n",
    "data = [[\"Beer\", \"T\", \"T\", \"T\"]\n",
    "        ,[\"Beer\", \"T\", \"F\", \"T\"]\n",
    "        ,[\"Vodka\", \"T\", \"F\", \"F\"]\n",
    "        ,[\"Vodka\", \"T\", \"F\", \"F\"]\n",
    "        ,[\"Vodka\", \"F\", \"T\", \"T\"]\n",
    "        ,[\"Vodka\", \"F\", \"F\", \"F\"]\n",
    "        ,[\"Vodka\", \"F\", \"T\", \"T\"]\n",
    "        ,[\"Vodka\", \"F\", \"T\", \"T\"]]\n",
    "\n",
    "make_tree(features, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
